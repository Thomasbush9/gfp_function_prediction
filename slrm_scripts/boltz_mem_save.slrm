#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=16
#SBATCH --gres=gpu:1
#SBATCH --mem=128GB
#SBATCH --partition=kempner_h100
#SBATCH --account=kempner_bsabatini_lab
#SBATCH --time=2:00:00
# Output log file (not an array job, so no %a needed):
#SBATCH --output=/n/home06/tbush/job_logs/%x.%A.out

INPUT_FILE=$1
OUTPUR_DIR=$2

echo "Starting Prediction Process on ${INPUT_FILE}"
echo "Predictions will be saved in ${OUTPUR_DIR}"
: "${BOLTZ_RECYCLING_STEPS:=8}"
: "${BOLTZ_DIFFUSION_SAMPLES:=10}"
BOLTZ_CACHE="/n/holylfs06/LABS/kempner_shared/Everyone/workflow/boltz/boltz_db"

BOLTZ_OUTPUT_DIR="${OUTPUR_DIR}/boltz_output"
mkdir -p "$BOLTZ_OUTPUT_DIR"

export TMPDIR="${SLURM_TMPDIR:-/tmp}"

# Set per-task Triton cache to avoid concurrent write conflicts
export TRITON_CACHE_DIR="${SLURM_TMPDIR:-/tmp}/triton_cache_${USER}_${JOB_ID}_${TASK_ID}"
mkdir -p "$TRITON_CACHE_DIR"

module load python/3.12.8-fasrc01 gcc/14.2.0-fasrc01 cuda/12.9.1-fasrc01 cudnn/9.10.2.21_cuda12-fasrc01
source "$(conda info --base)/etc/profile.d/conda.sh"
# prefer prefix activation
BOLTZ_END_PREFIX="${BOLTZ_END_PREFIX:-/n/home06/tbush/envs/boltz_mem}"
conda activate "$BOLTZ_END_PREFIX"

export CUDA_VISIBLE_DEVICES=0
export NUM_GPU_DEVICES=1

echo "Starting predictions"
boltz predict "$INPUT_FILE" --cache "$BOLTZ_CACHE" --out_dir "$BOLTZ_OUTPUT_DIR" --devices "$NUM_GPU_DEVICES" --accelerator gpu --recycling_steps "$BOLTZ_RECYCLING_STEPS" --diffusion_samples "$BOLTZ_DIFFUSION_SAMPLES" --override

echo "Predictions completed tot time: "
