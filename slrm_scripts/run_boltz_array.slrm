#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=16
#SBATCH --gpus-per-node=1
#SBATCH --mem=64GB
#SBATCH --partition=kempner_requeue
#SBATCH --account=kempner_bsabatini_lab
#SBATCH --time=2:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=thomasbush52@gmail.com
# Use array-aware log names to avoid clobbering:
#SBATCH --output=/n/home06/tbush/job_logs/%x.%A_%a.out

set -euo pipefail

# Select this task's chunk directory from the manifest
: "${SLURM_ARRAY_TASK_ID:?Need SLURM_ARRAY_TASK_ID}"
: "${MANIFEST:?Need MANIFEST exported from sbatch}"
: "${BASE_OUTPUT_DIR:?Need BASE_OUTPUT_DIR exported from sbatch}"
: "${BOLTZ_RECYCLING_STEPS:=8}"
: "${BOLTZ_DIFFUSION_SAMPLES:=10}"

CHUNK_DIR="$(sed -n "${SLURM_ARRAY_TASK_ID}p" "$MANIFEST")"
if [[ -z "${CHUNK_DIR}" || ! -d "${CHUNK_DIR}" ]]; then
  echo "Task ${SLURM_ARRAY_TASK_ID}: missing or invalid CHUNK_DIR from manifest."
  exit 1
fi

JOB_ID="${SLURM_ARRAY_JOB_ID:-${SLURM_JOB_ID:-manual}}"
TASK_ID="${SLURM_ARRAY_TASK_ID:-0}"

# Extract chunk number from CHUNK_DIR name (e.g., chunk_0 -> 0) to maintain consistency
CHUNK_NUM=$(basename "$CHUNK_DIR" | sed 's/chunk_//')

PROCESSED_PATHS_FILE="${BASE_OUTPUT_DIR}/processed_paths.txt"
TOT_FILES_BOLTZ="${BASE_OUTPUT_DIR}/tot_filesboltz.txt"
BOLTZ_CACHE="/n/holylfs06/LABS/kempner_shared/Everyone/workflow/boltz/boltz_db"
BOLTZ_OUTPUT_DIR="${BASE_OUTPUT_DIR}/boltz_output/chunk_${CHUNK_NUM}"

mkdir -p "$BOLTZ_OUTPUT_DIR"

# Use SLURM_TMPDIR for temporary files (auto-cleaned by SLURM)
export TMPDIR="${SLURM_TMPDIR:-/tmp}"

# Set per-task Triton cache to avoid concurrent write conflicts
export TRITON_CACHE_DIR="${SLURM_TMPDIR:-/tmp}/triton_cache_${USER}_${JOB_ID}_${TASK_ID}"
mkdir -p "$TRITON_CACHE_DIR"

export CUDA_VISIBLE_DEVICES=0
export NUM_GPU_DEVICES=1

# Load required modules
module load python/3.12.8-fasrc01 gcc/14.2.0-fasrc01 cuda/12.9.1-fasrc01 cudnn/9.10.2.21_cuda12-fasrc01
export PATH="/n/holylfs06/LABS/kempner_shared/Everyone/common_envs/miniconda3/envs/boltz/localcolabfold/colabfold-conda/bin:$PATH"
export COLABFOLD_DB=/n/holylfs06/LABS/kempner_shared/Everyone/workflow/boltz/colabfold_db

# Count yaml files in chunk directory
YAML_COUNT=$(find "$CHUNK_DIR" -maxdepth 1 -name "*.yaml" -type f | wc -l | tr -d ' ')

echo "==============================================="
echo "Task ${SLURM_ARRAY_TASK_ID}: Processing chunk directory"
echo "  Chunk dir: $CHUNK_DIR"
echo "  YAML files: ${YAML_COUNT}"
echo "  Output dir: $BOLTZ_OUTPUT_DIR"
echo "==============================================="

if (( YAML_COUNT == 0 )); then
  echo "WARNING: No .yaml files found in $CHUNK_DIR"
  exit 0
fi

# Activate boltz environment
mamba activate /n/holylfs06/LABS/kempner_shared/Everyone/common_envs/miniconda3/envs/boltz

# Run boltz predict on the chunk directory
echo "[$(date +%H:%M:%S)] Running boltz predict on chunk directory..."
echo "  Recycling steps: ${BOLTZ_RECYCLING_STEPS}"
echo "  Diffusion samples: ${BOLTZ_DIFFUSION_SAMPLES}"
if ! boltz predict "$CHUNK_DIR" --cache "$BOLTZ_CACHE" --out_dir "$BOLTZ_OUTPUT_DIR" --devices $NUM_GPU_DEVICES --accelerator gpu --recycling_steps "$BOLTZ_RECYCLING_STEPS" --diffusion_samples "$BOLTZ_DIFFUSION_SAMPLES" --override; then
  echo "ERROR: Boltz prediction failed for chunk directory $CHUNK_DIR"
  exit 1
fi

echo "[$(date +%H:%M:%S)] Boltz prediction completed successfully"

# Track successfully processed yaml files
# Use file locking to avoid race conditions when multiple tasks write simultaneously
(
  flock -x 200
  find "$CHUNK_DIR" -maxdepth 1 -name "*.yaml" -type f | while IFS= read -r yaml_file; do
    echo "$yaml_file" >> "$PROCESSED_PATHS_FILE"
  done
) 200>"${PROCESSED_PATHS_FILE}.lock"

rm -f "${PROCESSED_PATHS_FILE}.lock"

echo "==============================================="
echo "[$(date +%H:%M:%S)] Task ${SLURM_ARRAY_TASK_ID} complete"
echo "  Processed: ${YAML_COUNT} yaml files"
echo "==============================================="


